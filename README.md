# ğŸ± Food Recognition System (Soft Computing Project)

This project implements a deep learningâ€“based food image classification system using **InceptionV3**. It was developed as part of a soft computing course to demonstrate the application of convolutional neural networks (CNNs) in real-world computer vision problems.

---

## ğŸ¯ Objective

The goal of this system is to classify food images into **101 categories** with high accuracy. It leverages transfer learning, K-Fold cross-validation, and data augmentation to improve performance and robustness.

---

## ğŸ—‚ï¸ Project Structure

food-recognition-system/ â”‚ â”œâ”€â”€ dataset/ # Contains 'train', 'val', 'test' subfolders (not included in repo) â”‚ â”œâ”€â”€ train/ â”‚ â”œâ”€â”€ val/ â”‚ â””â”€â”€ test/ â”‚ â”œâ”€â”€ train.ipynb # Main notebook for training the model â”œâ”€â”€ splitting_rule.ipynb # Script to handle K-Fold splitting and dataset organization â”œâ”€â”€ model.keras # Final trained model (excluded from GitHub due to size) â”œâ”€â”€ requirements.txt # All dependencies â”œâ”€â”€ README.md â””â”€â”€ .gitignore


---

## ğŸ§  Model Summary

- **Base Model:** InceptionV3 (pretrained on ImageNet)
- **Input Size:** 299 x 299 x 3
- **Output Classes:** 101 food categories
- **Top Layers Added:**
  - GlobalAveragePooling2D
  - Dense(256, activation='relu')
  - Dropout(0.5)
  - Dense(101, activation='softmax')
- **Activation Functions:**
  - ReLU for intermediate layers
  - Softmax for the output layer

---

## âš™ï¸ Key Features

### âœ… Dataset Splitting
- Dataset is divided into:
  - **80,800 training images**
  - **10,100 validation images**
  - **10,100 test images**
- Images are equally distributed across all 101 classes.
- **5-Fold Cross-Validation** is applied using custom splitting logic (`splitting_rule.ipynb`).

### âœ… Data Augmentation
To enhance generalization and reduce overfitting, the training set is augmented using:

- Rotation
- Width/height shift
- Zoom
- Horizontal flip

Implemented using `ImageDataGenerator` from Keras.

### âœ… Overfitting Control
To prevent overfitting and improve learning:
- `Dropout(0.5)` used in dense layers
- `EarlyStopping` to stop training when validation loss stops improving
- `ModelCheckpoint` to save the best-performing model
- `ReduceLROnPlateau` to dynamically adjust learning rate on validation loss plateaus

---

## ğŸ§ª Evaluation Metrics

- **Training/Validation Accuracy and Loss per Epoch**
- **Training time per fold**
- **Final Model Size**
- **Confusion Matrix** and **Classification Report** per fold

---

## ğŸ§¾ Requirements

Install all dependencies with:

```bash
pip install -r requirements.txt
